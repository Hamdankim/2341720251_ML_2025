{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJjuOj5Bk3uzSwK+lGE05y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamdankim/2341720251_ML_2025/blob/main/JS14/TP_JS14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTMheqD6-Kce",
        "outputId": "330d80e6-2b95-4e32-efd6-0af1eccdff32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 553ms/step - accuracy: 0.2579 - loss: 2.0820 - val_accuracy: 0.3560 - val_loss: 1.9751\n",
            "Epoch 2/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 545ms/step - accuracy: 0.4612 - loss: 1.4729 - val_accuracy: 0.5478 - val_loss: 1.2724\n",
            "Epoch 3/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 546ms/step - accuracy: 0.5573 - loss: 1.2415 - val_accuracy: 0.6415 - val_loss: 1.0394\n",
            "Epoch 4/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 549ms/step - accuracy: 0.6212 - loss: 1.0787 - val_accuracy: 0.6959 - val_loss: 0.8587\n",
            "Epoch 5/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 552ms/step - accuracy: 0.6678 - loss: 0.9580 - val_accuracy: 0.7064 - val_loss: 0.8291\n",
            "Epoch 6/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 534ms/step - accuracy: 0.6980 - loss: 0.8671 - val_accuracy: 0.7263 - val_loss: 0.7854\n",
            "Epoch 7/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 541ms/step - accuracy: 0.7171 - loss: 0.8104 - val_accuracy: 0.7348 - val_loss: 0.7678\n",
            "Epoch 8/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 549ms/step - accuracy: 0.7376 - loss: 0.7575 - val_accuracy: 0.7703 - val_loss: 0.6755\n",
            "Epoch 9/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 546ms/step - accuracy: 0.7520 - loss: 0.7140 - val_accuracy: 0.7656 - val_loss: 0.6993\n",
            "Epoch 10/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 545ms/step - accuracy: 0.7640 - loss: 0.6787 - val_accuracy: 0.7760 - val_loss: 0.6908\n",
            "Epoch 11/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 547ms/step - accuracy: 0.7745 - loss: 0.6515 - val_accuracy: 0.7987 - val_loss: 0.5892\n",
            "Epoch 12/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 545ms/step - accuracy: 0.7853 - loss: 0.6208 - val_accuracy: 0.7875 - val_loss: 0.6300\n",
            "Epoch 13/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 548ms/step - accuracy: 0.7930 - loss: 0.6006 - val_accuracy: 0.7978 - val_loss: 0.5982\n",
            "Epoch 14/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 546ms/step - accuracy: 0.8043 - loss: 0.5714 - val_accuracy: 0.8167 - val_loss: 0.5523\n",
            "Epoch 15/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 543ms/step - accuracy: 0.8081 - loss: 0.5602 - val_accuracy: 0.8057 - val_loss: 0.5825\n",
            "Epoch 16/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 548ms/step - accuracy: 0.8132 - loss: 0.5405 - val_accuracy: 0.8011 - val_loss: 0.5915\n",
            "Epoch 17/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 541ms/step - accuracy: 0.8166 - loss: 0.5267 - val_accuracy: 0.8000 - val_loss: 0.6093\n",
            "Epoch 18/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 538ms/step - accuracy: 0.8252 - loss: 0.5051 - val_accuracy: 0.8176 - val_loss: 0.5521\n",
            "Epoch 19/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 536ms/step - accuracy: 0.8298 - loss: 0.4969 - val_accuracy: 0.8287 - val_loss: 0.5152\n",
            "Epoch 20/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 532ms/step - accuracy: 0.8338 - loss: 0.4798 - val_accuracy: 0.8278 - val_loss: 0.5286\n",
            "Epoch 21/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 547ms/step - accuracy: 0.8408 - loss: 0.4620 - val_accuracy: 0.8209 - val_loss: 0.5629\n",
            "Epoch 22/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 545ms/step - accuracy: 0.8375 - loss: 0.4722 - val_accuracy: 0.8277 - val_loss: 0.5136\n",
            "Epoch 23/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 545ms/step - accuracy: 0.8426 - loss: 0.4480 - val_accuracy: 0.8317 - val_loss: 0.5199\n",
            "Epoch 24/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 540ms/step - accuracy: 0.8454 - loss: 0.4470 - val_accuracy: 0.8361 - val_loss: 0.5066\n",
            "Epoch 25/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 541ms/step - accuracy: 0.8500 - loss: 0.4286 - val_accuracy: 0.8270 - val_loss: 0.5221\n",
            "313/313 - 18s - 58ms/step - accuracy: 0.8270 - loss: 0.5221\n",
            "Akurasi testing: 0.8270000219345093\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images/255.0, test_images/255.0\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(32,32,3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.35),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    epochs=25, batch_size=64)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Akurasi testing:\", test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images/255.0, test_images/255.0\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(32,32,3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.35),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    epochs=25, batch_size=64)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Akurasi testing:\", test_acc)\n"
      ],
      "metadata": {
        "id": "SCkV1lYS-MMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208cd9f2-bdde-41ff-b70f-377236d8b218"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 559ms/step - accuracy: 0.2630 - loss: 2.0754 - val_accuracy: 0.4470 - val_loss: 1.5282\n",
            "Epoch 2/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 550ms/step - accuracy: 0.4677 - loss: 1.4349 - val_accuracy: 0.5728 - val_loss: 1.1863\n",
            "Epoch 3/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 552ms/step - accuracy: 0.5666 - loss: 1.2116 - val_accuracy: 0.6246 - val_loss: 1.0662\n",
            "Epoch 4/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 545ms/step - accuracy: 0.6288 - loss: 1.0510 - val_accuracy: 0.6641 - val_loss: 0.9696\n",
            "Epoch 5/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 545ms/step - accuracy: 0.6701 - loss: 0.9345 - val_accuracy: 0.6985 - val_loss: 0.8814\n",
            "Epoch 6/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 551ms/step - accuracy: 0.7037 - loss: 0.8680 - val_accuracy: 0.7174 - val_loss: 0.8218\n",
            "Epoch 7/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 550ms/step - accuracy: 0.7238 - loss: 0.7995 - val_accuracy: 0.7694 - val_loss: 0.6652\n",
            "Epoch 8/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 554ms/step - accuracy: 0.7467 - loss: 0.7465 - val_accuracy: 0.7379 - val_loss: 0.7766\n",
            "Epoch 9/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 548ms/step - accuracy: 0.7572 - loss: 0.7022 - val_accuracy: 0.7806 - val_loss: 0.6604\n",
            "Epoch 10/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 549ms/step - accuracy: 0.7764 - loss: 0.6530 - val_accuracy: 0.7717 - val_loss: 0.6563\n",
            "Epoch 11/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 558ms/step - accuracy: 0.7840 - loss: 0.6311 - val_accuracy: 0.7831 - val_loss: 0.6458\n",
            "Epoch 12/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 556ms/step - accuracy: 0.7948 - loss: 0.5967 - val_accuracy: 0.8053 - val_loss: 0.5633\n",
            "Epoch 13/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 557ms/step - accuracy: 0.7985 - loss: 0.5800 - val_accuracy: 0.8130 - val_loss: 0.5563\n",
            "Epoch 14/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 553ms/step - accuracy: 0.8087 - loss: 0.5625 - val_accuracy: 0.8029 - val_loss: 0.6114\n",
            "Epoch 15/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 555ms/step - accuracy: 0.8157 - loss: 0.5354 - val_accuracy: 0.8176 - val_loss: 0.5592\n",
            "Epoch 16/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 554ms/step - accuracy: 0.8225 - loss: 0.5200 - val_accuracy: 0.8093 - val_loss: 0.5648\n",
            "Epoch 17/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 548ms/step - accuracy: 0.8241 - loss: 0.5117 - val_accuracy: 0.8104 - val_loss: 0.5970\n",
            "Epoch 18/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 555ms/step - accuracy: 0.8351 - loss: 0.4843 - val_accuracy: 0.8239 - val_loss: 0.5432\n",
            "Epoch 19/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 553ms/step - accuracy: 0.8349 - loss: 0.4771 - val_accuracy: 0.8348 - val_loss: 0.5065\n",
            "Epoch 20/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 555ms/step - accuracy: 0.8395 - loss: 0.4692 - val_accuracy: 0.8368 - val_loss: 0.5007\n",
            "Epoch 21/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 546ms/step - accuracy: 0.8452 - loss: 0.4493 - val_accuracy: 0.8218 - val_loss: 0.5456\n",
            "Epoch 22/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 548ms/step - accuracy: 0.8483 - loss: 0.4422 - val_accuracy: 0.8274 - val_loss: 0.5495\n",
            "Epoch 23/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 556ms/step - accuracy: 0.8492 - loss: 0.4379 - val_accuracy: 0.8454 - val_loss: 0.4712\n",
            "Epoch 24/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 554ms/step - accuracy: 0.8500 - loss: 0.4287 - val_accuracy: 0.8330 - val_loss: 0.5281\n",
            "Epoch 25/25\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 538ms/step - accuracy: 0.8576 - loss: 0.4119 - val_accuracy: 0.8344 - val_loss: 0.5154\n",
            "313/313 - 18s - 57ms/step - accuracy: 0.8344 - loss: 0.5154\n",
            "Akurasi testing: 0.8343999981880188\n"
          ]
        }
      ]
    }
  ]
}